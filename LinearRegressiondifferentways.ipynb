{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LinearRegressiondifferentways.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvGiSbqMpGoVft/IEKIGjp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yighu/CodeSamples/blob/master/LinearRegressiondifferentways.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf79CcR5l5of"
      },
      "source": [
        "What Is Linear Regression \n",
        "The implementation \n",
        "* Step by Step (Traditional)\n",
        "* Using Keras \n",
        "* Using Tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X6MM1jaF2x0"
      },
      "source": [
        "Linear Regression Explained\n",
        "\n",
        "Import the packages and the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrbJByxCGMmZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Yi_V9QJxCK"
      },
      "source": [
        "Define the hypothesis and the cost function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11qT59ADGUMD"
      },
      "source": [
        "def hypothesis(theta, X):\n",
        "    return theta[0] + theta[1]*X\n",
        "def cost_calc(theta, X, y):\n",
        "    return (1/2*m) * np.sum((hypothesis(theta, X) - y)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIRR8CQIGdlE"
      },
      "source": [
        "Create some simulated Data\n",
        "With theta=[0.5,5] plus some noice using random numner\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smgaqDCnG4hs"
      },
      "source": [
        "\n",
        "x=x=random.randint(100, size=(500))/100\n",
        "noise=random.randint(20, size=(500))/20\n",
        "y=0.5 + 5*x +noise\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk82e75BOhvM"
      },
      "source": [
        "print(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hElcCz2J0No"
      },
      "source": [
        " Calculate the number of training data as the length of the DataFrame. And then define the function for gradient descent. In this function, we will update the theta values until the cost function is it’s minimum. It may take any number of iteration. In each iteration, it will update the theta values and with each updated theta values we will calculate the cost to keep track of the cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlyZADzMJr-O"
      },
      "source": [
        "m = len(x)\n",
        "def gradient_descent(theta, X, y, epoch, alpha):\n",
        "    cost = []\n",
        "    i = 0\n",
        "    while i < epoch:\n",
        "        hx = hypothesis(theta, X)\n",
        "        theta[0] -= alpha*(sum(hx-y)/m)\n",
        "        theta[1] -= (alpha * np.sum((hx - y) * X))/m\n",
        "        cost.append(cost_calc(theta, X, y))\n",
        "        i += 1\n",
        "    return theta, cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnnOclOZJ_n9"
      },
      "source": [
        "Finally, define the predict function. It will get the updated theta from the gradient descent function and predict the hypothesis or the predicted output variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuzpME5_KCxr"
      },
      "source": [
        "def predict(theta, X, y, epoch, alpha):\n",
        "    theta, cost = gradient_descent(theta, X, y, epoch, alpha)\n",
        "    return hypothesis(theta, X), cost, theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBJYJwJjKHOl"
      },
      "source": [
        "Using the predict function, find the hypothesis, cost, and updated theta values. I choose the learning rate as 0.01 and I will run this algorithm for 2000 epochs or iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mfz73CtKUCX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY8M3F3zKrk_"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.scatter(df[0], df[1], label = 'Original y')\n",
        "plt.scatter(df[0], y_predict, label = 'predicted y')\n",
        "plt.legend(loc = \"upper left\")\n",
        "plt.xlabel(\"input feature\")\n",
        "plt.ylabel(\"Original and Predicted Output\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAxYWFtCKsq6"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.scatter(x, y, label = 'Original y')\n",
        "#plt.scatter(df[0], y_predict, label = 'predicted y')\n",
        "plt.legend(loc = \"upper left\")\n",
        "plt.xlabel(\"input feature\")\n",
        "plt.ylabel(\"Original and Predicted Output\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7vvnhPKUVG"
      },
      "source": [
        "theta = [0.1,1.1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wuRQGeLKKi9"
      },
      "source": [
        "y_predict, cost, theta1 = predict(theta, x, y, 2000, 0.0005)\n",
        "#print(type(cost))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa83z1TNNl5f"
      },
      "source": [
        "print(type(cost))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uD0vVtjNyVh"
      },
      "source": [
        "print(cost[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYU5A3VPPxrw"
      },
      "source": [
        "cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6qS0VpLPgon"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.scatter(x, y, label = 'Original y')\n",
        "plt.scatter(x, y_predict, label = 'predicted y')\n",
        "plt.legend(loc = \"upper left\")\n",
        "plt.xlabel(\"input feature\")\n",
        "plt.ylabel(\"Original and Predicted Output\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d00Fu2zyqmQX"
      },
      "source": [
        "print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5i8m5YOP8cm"
      },
      "source": [
        " Remember, we kept track of the cost function in each iteration. Let’s plot the cost function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrDQlkvP9CG"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(range(0, len(cost)), cost)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05flNt0GmM99"
      },
      "source": [
        "Implement with Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gih3xF8mRxM"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP982d0ZnLHh"
      },
      "source": [
        "create Keras model for linear regression, use a single Dense layer with a linear activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq2xl2Lqmvpk"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1))\n",
        "model.add(Activation('linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgIu8IeFndfb"
      },
      "source": [
        "Compile the model with SGD optimizer with a learning rate of 0.03 and set the mean squared error as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiliPl4Hm8af"
      },
      "source": [
        "sgd = SGD(0.03)\n",
        "model.compile(loss='mse',optimizer=sgd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLcukv1GnpuL"
      },
      "source": [
        "Now we can use the model.fit() function to train the model using\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOI1XmDnqt6"
      },
      "source": [
        "history = model.fit(x,y,epochs=500,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO1eR1iWnxTo"
      },
      "source": [
        "As the model is trained, we can now use the predict method to make predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q9ikNbpn1Ek"
      },
      "source": [
        "pred = model.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IaP09C5nJS8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8C5R41coNaC"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.scatter(x, y, label = 'Original y')\n",
        "plt.scatter(x, pred, label = 'predicted y')\n",
        "plt.legend(loc = \"upper left\")\n",
        "plt.xlabel(\"input feature\")\n",
        "plt.ylabel(\"Original and Predicted Output\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igQX2Hu-q3p0"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IV3NSXJrAkv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qER5ws87rBbL"
      },
      "source": [
        "Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co8AJZq4rEFl"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-JvfTjZsRCF"
      },
      "source": [
        "class LinearModel:\n",
        "    def __call__(self, x):\n",
        "        return self.Weight * x + self.Bias\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.Weight = tf.Variable(110.0)\n",
        "        self.Bias = tf.Variable(120.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L6EqcVNsWHG"
      },
      "source": [
        "def loss(y, pred):\n",
        "    return tf.reduce_mean(tf.square(y - pred))\n",
        "\n",
        "def train(linear_model, x, y, lr=0.12):\n",
        "    with tf.GradientTape() as t:\n",
        "        current_loss = loss(y, linear_model(x))\n",
        "\n",
        "    lr_weight, lr_bias = t.gradient(current_loss, [linear_model.Weight, linear_model.Bias])\n",
        "    linear_model.Weight.assign_sub(lr * lr_weight)\n",
        "    linear_model.Bias.assign_sub(lr * lr_bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXQQ63CesZ6x"
      },
      "source": [
        "linear_model = LinearModel()\n",
        "Weights, Biases = [], []\n",
        "losed =[]\n",
        "epocs=[]\n",
        "epochs = 2000\n",
        "for epoch_count in range(epochs):\n",
        "    Weights.append(linear_model.Weight.numpy()) \n",
        "    Biases.append(linear_model.Bias.numpy())\n",
        "    real_loss = loss(y, linear_model(x))\n",
        "    \n",
        "    train(linear_model, x, y, lr=0.12)\n",
        "    print(f\"Epoch count {epoch_count}: Loss value: {real_loss.numpy()}\")\n",
        "    epocs.append(epoch_count)\n",
        "    losed.append(real_loss.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iW-vQ0EsgSM"
      },
      "source": [
        "linear_model.Weight.numpy(), linear_model.Bias.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBkAt9DiskI-"
      },
      "source": [
        "RMSE = loss(y, linear_model(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AJDxvBvsk2R"
      },
      "source": [
        "RMSE.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZAkOsSusqlr"
      },
      "source": [
        "fitted=linear_model(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOXP6qXUtAyC"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.scatter(x, y, label = 'Original y')\n",
        "plt.scatter(x, fitted, label = 'predicted y')\n",
        "plt.legend(loc = \"upper left\")\n",
        "plt.xlabel(\"input feature\")\n",
        "plt.ylabel(\"Original and Predicted Output\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRPzGvJGtF12"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(range(0, len(losed)), losed)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}